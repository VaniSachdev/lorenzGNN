{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 00:27:51.756959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts\n",
    "from utils.jraph_training import rollout_loss, train_step, train_step_fn, evaluate_model, train_and_evaluate, create_dataset #, rollout_loss_batched, \n",
    "from utils.jraph_models import MLPBlock, MLPGraphNetwork\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from flax_gnn_example.configs import mlpblock_test\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the gn core model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.helpers import get_sample_data, state_setup_helper\n",
    "def forward_pass_helper_test(model):\n",
    "    \"\"\" Helper function to test the forward pass for an arbitrary model. \n",
    "    \n",
    "    \"\"\"\n",
    "    # get sample graph\n",
    "    sample_dataset, _ = get_sample_data()\n",
    "    sample_input_window = sample_dataset['train']['inputs'][0]\n",
    "    sample_target_window = sample_dataset['train']['targets'][0]\n",
    "\n",
    "    # set up state object, which helps us keep track of the model, params, and optimizer\n",
    "    state = state_setup_helper(model)\n",
    "\n",
    "    pred_graph = state.apply_fn(state.params, sample_input_window)\n",
    "\n",
    "    return state, pred_graph, sample_dataset\n",
    "    # first_target_graph = sample_target_window[0]\n",
    "\n",
    "    # # check that the forward_pass_helper_test shape of the node features is correct\n",
    "    # self.assertEqual(pred_graph.nodes.shape, first_target_graph.nodes.shape)\n",
    "\n",
    "    # # check edge features did not change\n",
    "    # self.assertTrue(\n",
    "    #     jnp.array_equal(pred_graph.edges, first_target_graph.edges))\n",
    "\n",
    "    # # check global features did not change\n",
    "    # self.assertTrue(\n",
    "    #     jnp.array_equal(pred_graph.globals, first_target_graph.globals))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MLPGraphNetwork(n_blocks=1, share_params=False)\n",
    "\n",
    "# get sample graph\n",
    "sample_dataset, _ = get_sample_data()\n",
    "sample_input_window = sample_dataset['train']['inputs'][0]\n",
    "sample_target_window = sample_dataset['train']['targets'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(174)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    172 \u001b[0;31m        \u001b[0;31m# Apply a Graph Network once for each message-passing round.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 174 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_window_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m        \u001b[0;31m# TODO: do we need skip connections or layer_norm here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "[GraphsTuple(nodes=Traced<ShapedArray(float32[36,2])>with<DynamicJaxprTrace(level=1/0)>, edges=Traced<ShapedArray(float32[180,1])>with<DynamicJaxprTrace(level=1/0)>, receivers=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, senders=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, globals=Traced<ShapedArray(float32[1,1])>with<DynamicJaxprTrace(level=1/0)>, n_node=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>, n_edge=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>), GraphsTuple(nodes=Traced<ShapedArray(float32[36,2])>with<DynamicJaxprTrace(level=1/0)>, edges=Traced<ShapedArray(float32[180,1])>with<DynamicJaxprTrace(level=1/0)>, receivers=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, senders=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, globals=Traced<ShapedArray(float32[1,1])>with<DynamicJaxprTrace(level=1/0)>, n_node=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>, n_edge=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>), GraphsTuple(nodes=Traced<ShapedArray(float32[36,2])>with<DynamicJaxprTrace(level=1/0)>, edges=Traced<ShapedArray(float32[180,1])>with<DynamicJaxprTrace(level=1/0)>, receivers=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, senders=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, globals=Traced<ShapedArray(float32[1,1])>with<DynamicJaxprTrace(level=1/0)>, n_node=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>, n_edge=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>)]\n",
      "GraphsTuple(nodes=Traced<ShapedArray(float32[36,2])>with<DynamicJaxprTrace(level=1/0)>, edges=Traced<ShapedArray(float32[180,1])>with<DynamicJaxprTrace(level=1/0)>, receivers=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, senders=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, globals=Traced<ShapedArray(float32[1,1])>with<DynamicJaxprTrace(level=1/0)>, n_node=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>, n_edge=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>)\n",
      "input_graph GraphsTuple(nodes=Traced<ShapedArray(float32[36,2])>with<DynamicJaxprTrace(level=1/0)>, edges=Traced<ShapedArray(float32[180,1])>with<DynamicJaxprTrace(level=1/0)>, receivers=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, senders=Traced<ShapedArray(int32[180])>with<DynamicJaxprTrace(level=1/0)>, globals=Traced<ShapedArray(float32[1,1])>with<DynamicJaxprTrace(level=1/0)>, n_node=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>, n_edge=Traced<ShapedArray(int32[1])>with<DynamicJaxprTrace(level=1/0)>)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(110)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    108 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_graph'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    109 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 110 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0;31m# revert edge features to their original values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    112 \u001b[0;31m        \u001b[0;31m# we want the edges to be encoded/processed by the update_edge_fn internally as part of the processing for the node features, but we only use the encoded edges internally and don't want it to affect the actual graph structure of the data because we know that it is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# set up state object, which helps us keep track of the model, params, and optimizer\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "params1 = jax.jit(model1.init)(init_rng, sample_input_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(174)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    172 \u001b[0;31m        \u001b[0;31m# TODO: do we need skip connections or layer_norm here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 174 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_graphs_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model2 = MLPGraphNetwork(n_blocks=2, share_params=False)\n",
    "\n",
    "params2 = jax.jit(model2.init)(init_rng, sample_input_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(174)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    172 \u001b[0;31m        \u001b[0;31m# TODO: do we need skip connections or layer_norm here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 174 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_graphs_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    175 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    176 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model10 = MLPGraphNetwork(n_blocks=10, share_params=False)\n",
    "params10 = jax.jit(model10.init)(init_rng, sample_input_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MLPBlock_0', 'MLPBlock_1', 'MLPBlock_2', 'MLPBlock_3', 'MLPBlock_4', 'MLPBlock_5', 'MLPBlock_6', 'MLPBlock_7', 'MLPBlock_8', 'MLPBlock_9'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params10['params'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
