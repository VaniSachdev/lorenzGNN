{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test if GPU is working... we will run this notebook on both a server with GPU and on my local machine with only CPU. \n",
    "\n",
    "This notebook is identical to gpu_test and gpu_test_with_flags\n",
    "\n",
    "On the server, we check nvidia-smi to see if it is actually using GPU. \n",
    "\n",
    "Then, we compare runtimes for this notebook on GPU vs CPU to make sure that GPU isn't inadvertently making things slower (e.g. by repeatedly moving data btwn CPU/GPU, etc). Also we should check how much faster GPU makes things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.jraph_training import train_and_evaluate_with_data, create_dataset\n",
    "# from utils.jraph_models import MLPGraphNetwork\n",
    "from utils.jraph_data import print_graph_fts\n",
    "from utils.jraph_vis import plot_predictions\n",
    "from utils.hyperparam_tuning import remove_bad_trials, get_best_trial_config, get_best_trial_workdir\n",
    "import ml_collections\n",
    "import optuna \n",
    "from flax import linen as nn\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up functions for optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"experiments/tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, study_name, datasets):\n",
    "    \"\"\" Defines the objective function to be optimized over, aka the validation loss of a model.\n",
    "    \n",
    "        Args:\n",
    "            trial: object which characterizes the current run \n",
    "            datasets: dictionary of data. we explicitly pass this in so that we don't have to waste runtime regenerating the same dataset over and over. \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    # create config \n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    # Optimizer.\n",
    "    # config.optimizer = \"adam\"\n",
    "    config.optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    config.learning_rate = trial.suggest_float('learning_rate', 1e-4, 5e-2, \n",
    "                                               log=True)\n",
    "    if config.optimizer == \"sgd\":\n",
    "        config.momentum = trial.suggest_float('momentum', 0, 0.999) # upper bound is inclusive, and we want to exclude a momentum of 1 because that would yield no decay \n",
    "\n",
    "    # Data params that are used in training \n",
    "    config.output_steps = 4\n",
    "\n",
    "    # Training hyperparameters.\n",
    "    config.batch_size = 1 # variable currently not used\n",
    "    config.epochs = 200\n",
    "    config.log_every_epochs = 5\n",
    "    config.eval_every_epochs = 5\n",
    "    config.checkpoint_every_epochs = 10\n",
    "\n",
    "    # GNN hyperparameters.\n",
    "    config.model = 'MLPBlock'\n",
    "    config.dropout_rate = trial.suggest_float('dropout_rate', 0, 0.6)\n",
    "    config.skip_connections = False # This was throwing a broadcast error in add_graphs_tuples_nodes when this was set to True\n",
    "    config.layer_norm = False # TODO perhaps we want to turn on later\n",
    "    config.activation = trial.suggest_categorical(\n",
    "        'activation', [\"relu\", \"elu\", \"leaky_relu\"])\n",
    "    \n",
    "    # choose the hidden layer feature size using powers of 2 \n",
    "    config.edge_features = (\n",
    "        2**trial.suggest_int(\"edge_mlp_1_power\", 1, 3), # range 2 - 8; upper bound is inclusive\n",
    "        2**trial.suggest_int(\"edge_mlp_2_power\", 1, 3), # range 2 - 8\n",
    "    )\n",
    "    config.node_features = (\n",
    "        2**trial.suggest_int(\"node_mlp_1_power\", 1, 8), # range 2 - 512\n",
    "        2**trial.suggest_int(\"node_mlp_2_power\", 1, 8), # range 2 - 512\n",
    "        2) \n",
    "    # note the last feature size will be the number of features that the graph predicts\n",
    "    config.global_features = None\n",
    "\n",
    "    # generate a workdir \n",
    "    # TODO: check if we actually care about referencing this in the future or if we can just create a temp dir \n",
    "    workdir=os.path.join(CHECKPOINT_PATH, study_name, f\"trial_{trial.number}\")\n",
    "\n",
    "    # run training \n",
    "    state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(config=config, workdir=workdir, datasets=datasets, trial=trial)\n",
    "    \n",
    "    # retrieve and return val loss (MSE)\n",
    "    # print(\"eval_metrics_dict['val'].loss\", eval_metrics_dict['val'].loss)\n",
    "    # print(\"eval_metrics_dict['val'].compute()['loss']\", eval_metrics_dict['val'].compute()['loss'])\n",
    "    # print()\n",
    "    end = datetime.now()\n",
    "\n",
    "    print(f\"objective func took {end - start} to run\")\n",
    "    return eval_metrics_dict['val'].compute()['loss']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.n_samples=10_000\n",
    "    config.input_steps=1\n",
    "    config.output_delay=8 # predict 24 hrs into the future \n",
    "    config.output_steps=4\n",
    "    config.timestep_duration=3 # equivalent to 3 hours\n",
    "    # note a 3 hour timestep resolution would be 5*24/3=40\n",
    "    # if the time_resolution is 120, then a sampling frequency of 3 would achieve a 3 hour timestep \n",
    "    config.sample_buffer = -1 * (config.input_steps + config.output_delay + config.output_steps - 1) # negative buffer so that our sample input are continuous (i.e. the first sample would overlap a bit with consecutive samples) \n",
    "        # number of timesteps strictly between the end \n",
    "        # of one full sample and the start of the next sample\n",
    "    config.time_resolution=120 # the number of \n",
    "                # raw data points generated per time unit, equivalent to the \n",
    "                # number of data points generated per 5 days in the simulation\n",
    "    config.init_buffer_samples=100\n",
    "    config.train_pct=0.7\n",
    "    config.val_pct=0.2\n",
    "    config.test_pct=0.1\n",
    "    config.K=36\n",
    "    config.F=8\n",
    "    config.c=10\n",
    "    config.b=10\n",
    "    config.h=1\n",
    "    config.seed=42\n",
    "    config.normalize=True\n",
    "    config.fully_connected_edges=False\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_study(study_name):\n",
    "    # generate dataset \n",
    "    data_start = datetime.now()\n",
    "    dataset_config = get_data_config()\n",
    "    datasets = create_dataset(dataset_config)\n",
    "    data_end = datetime.now()\n",
    "    print(f\"dataset took {data_end - data_start} time to generate\")\n",
    "    \n",
    "    print_graph_fts(datasets['train']['inputs'][0][0])\n",
    "\n",
    "    # get the objective function that reuses the pre-generated datasets \n",
    "    objective_partial = partial(objective, study_name=study_name, \n",
    "                                datasets=datasets)\n",
    "\n",
    "    # run optimization study\n",
    "    db_path = os.path.join(CHECKPOINT_PATH, study_name, \"optuna_hparam_search.db\")\n",
    "    if not os.path.exists(os.path.join(CHECKPOINT_PATH, study_name)):\n",
    "        os.makedirs(os.path.join(CHECKPOINT_PATH, study_name))\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=f'sqlite:///{db_path}', # generates a new db if it doesn't exist\n",
    "        direction='minimize',\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5, \n",
    "            n_warmup_steps=50,\n",
    "            ), \n",
    "        load_if_exists=True, \n",
    "    )\n",
    "    \n",
    "    return study, objective_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset took 0:00:33.731221 time to generate\n",
      "Number of nodes: 36\n",
      "Number of edges: 180\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (180, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 14:44:12,549] A new study created in RDB with name: hparam_study_cpu\n"
     ]
    }
   ],
   "source": [
    "# get study\n",
    "study_cpu, objective_partial = prepare_study(study_name=\"hparam_study_cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 15:01:21,973] Trial 0 finished with value: 0.9284715056419373 and parameters: {'optimizer': 'adam', 'learning_rate': 0.012547699916066543, 'dropout_rate': 0.19775912811101745, 'activation': 'relu', 'edge_mlp_1_power': 1, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 1, 'node_mlp_2_power': 3}. Best is trial 0 with value: 0.9284715056419373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective func took 0:17:08.779966 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:loss is nan for step 1 (in epoch 0)\n",
      "[I 2023-12-08 15:01:28,258] Trial 1 pruned. \n",
      "[I 2023-12-08 15:20:07,120] Trial 2 finished with value: 0.6470192670822144 and parameters: {'optimizer': 'adam', 'learning_rate': 0.0001430254612246361, 'dropout_rate': 0.1740112499388723, 'activation': 'elu', 'edge_mlp_1_power': 2, 'edge_mlp_2_power': 2, 'node_mlp_1_power': 4, 'node_mlp_2_power': 6}. Best is trial 2 with value: 0.6470192670822144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective func took 0:18:38.793092 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:loss is nan for step 5 (in epoch 0)\n",
      "[I 2023-12-08 15:20:12,720] Trial 3 pruned. \n",
      "WARNING:absl:loss is nan for step 1 (in epoch 0)\n",
      "[I 2023-12-08 15:20:17,678] Trial 4 pruned. \n",
      "WARNING:absl:loss is nan for step 1 (in epoch 0)\n",
      "[I 2023-12-08 15:20:22,431] Trial 5 pruned. \n",
      "[I 2023-12-08 15:37:31,696] Trial 6 finished with value: 0.7997133731842041 and parameters: {'optimizer': 'adam', 'learning_rate': 0.00018987044146619007, 'dropout_rate': 0.4604022443126251, 'activation': 'elu', 'edge_mlp_1_power': 2, 'edge_mlp_2_power': 3, 'node_mlp_1_power': 6, 'node_mlp_2_power': 2}. Best is trial 2 with value: 0.6470192670822144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective func took 0:17:09.181878 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 15:50:22,462] Trial 7 finished with value: 0.928964376449585 and parameters: {'optimizer': 'sgd', 'learning_rate': 0.009788386865088861, 'momentum': 0.9177190034137848, 'dropout_rate': 0.1748933839199729, 'activation': 'relu', 'edge_mlp_1_power': 1, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 6, 'node_mlp_2_power': 1}. Best is trial 2 with value: 0.6470192670822144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective func took 0:12:50.697427 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 16:18:15,647] Trial 8 finished with value: 0.6276121139526367 and parameters: {'optimizer': 'adam', 'learning_rate': 0.00021356616764865534, 'dropout_rate': 0.05124536391736096, 'activation': 'relu', 'edge_mlp_1_power': 3, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 3, 'node_mlp_2_power': 8}. Best is trial 8 with value: 0.6276121139526367.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective func took 0:27:53.070867 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-12-08 17:04:05,134] Trial 9 failed with parameters: {'optimizer': 'adam', 'learning_rate': 0.0001991131146678531, 'dropout_rate': 0.0008297463805169602, 'activation': 'elu', 'edge_mlp_1_power': 1, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 8, 'node_mlp_2_power': 8} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/py/716jgpq538x2wf_s8t__x9b80000gn/T/ipykernel_95478/2020598259.py\", line 55, in objective\n",
      "    state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(config=config, workdir=workdir, datasets=datasets, trial=trial)\n",
      "  File \"/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_training.py\", line 466, in train_and_evaluate_with_data\n",
      "    state, metrics_update, _ = train_step(\n",
      "  File \"/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/jax/_src/tree_util.py\", line 700, in flatten_func_impl\n",
      "    key_children, treedef = flatten_with_keys(tree)\n",
      "  File \"/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/flax/struct.py\", line 123, in iterate_clz_with_keys\n",
      "    data = tuple(\n",
      "  File \"/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/flax/struct.py\", line 124, in <genexpr>\n",
      "    (jax.tree_util.GetAttrKey(name), getattr(x, name))\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-08 17:04:05,188] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/cpu_test.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study_cpu\u001b[39m.\u001b[39;49moptimize(objective_partial, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39mlen\u001b[39;49m(study_cpu\u001b[39m.\u001b[39;49mtrials), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/cpu_test.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m workdir\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, study_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrial_\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# run training \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m state, train_metrics, eval_metrics_dict \u001b[39m=\u001b[39m train_and_evaluate_with_data(config\u001b[39m=\u001b[39;49mconfig, workdir\u001b[39m=\u001b[39;49mworkdir, datasets\u001b[39m=\u001b[39;49mdatasets, trial\u001b[39m=\u001b[39;49mtrial)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# retrieve and return val loss (MSE)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# print(\"eval_metrics_dict['val'].loss\", eval_metrics_dict['val'].loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# print(\"eval_metrics_dict['val'].compute()['loss']\", eval_metrics_dict['val'].compute()['loss'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# print()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/h.lu/Documents/_code/_research%20lorenz%20code/lorenzGNN/cpu_test.ipynb#X15sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m end \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_training.py:466\u001b[0m, in \u001b[0;36mtrain_and_evaluate_with_data\u001b[0;34m(config, workdir, datasets, trial)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m# Perform one step of training.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mStepTraceAnnotation(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep):\n\u001b[1;32m    465\u001b[0m     \u001b[39m# graphs = jax.tree_util.tree_map(np.asarray, next(train_iter))\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     state, metrics_update, _ \u001b[39m=\u001b[39m train_step(\n\u001b[1;32m    467\u001b[0m         state\u001b[39m=\u001b[39;49mstate, \n\u001b[1;32m    468\u001b[0m         n_rollout_steps\u001b[39m=\u001b[39;49mn_rollout_steps, \n\u001b[1;32m    469\u001b[0m         input_window_graphs\u001b[39m=\u001b[39;49minput_window_graphs, \n\u001b[1;32m    470\u001b[0m         target_window_graphs\u001b[39m=\u001b[39;49mtarget_window_graphs, \n\u001b[1;32m    471\u001b[0m         rngs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: dropout_rng}\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m jnp\u001b[39m.\u001b[39misnan(metrics_update\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mtotal):\n\u001b[1;32m    474\u001b[0m         \u001b[39m# TODO is it ok to raise the prune even if the pruner doesn't say should prune? \u001b[39;00m\n\u001b[1;32m    475\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss is nan for step \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m (in epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/jax/_src/tree_util.py:700\u001b[0m, in \u001b[0;36mregister_pytree_with_keys.<locals>.flatten_func_impl\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflatten_func_impl\u001b[39m(tree):\n\u001b[0;32m--> 700\u001b[0m   key_children, treedef \u001b[39m=\u001b[39m flatten_with_keys(tree)\n\u001b[1;32m    701\u001b[0m   \u001b[39mreturn\u001b[39;00m [c \u001b[39mfor\u001b[39;00m _, c \u001b[39min\u001b[39;00m key_children], treedef\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/flax/struct.py:123\u001b[0m, in \u001b[0;36mdataclass.<locals>.iterate_clz_with_keys\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miterate_clz_with_keys\u001b[39m(x):\n\u001b[1;32m    122\u001b[0m   meta \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mgetattr\u001b[39m(x, name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m meta_fields)\n\u001b[0;32m--> 123\u001b[0m   data \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\n\u001b[1;32m    124\u001b[0m       (jax\u001b[39m.\u001b[39;49mtree_util\u001b[39m.\u001b[39;49mGetAttrKey(name), \u001b[39mgetattr\u001b[39;49m(x, name))\n\u001b[1;32m    125\u001b[0m       \u001b[39mfor\u001b[39;49;00m name \u001b[39min\u001b[39;49;00m data_fields\n\u001b[1;32m    126\u001b[0m   )\n\u001b[1;32m    127\u001b[0m   \u001b[39mreturn\u001b[39;00m data, meta\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/flax/struct.py:124\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miterate_clz_with_keys\u001b[39m(x):\n\u001b[1;32m    122\u001b[0m   meta \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mgetattr\u001b[39m(x, name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m meta_fields)\n\u001b[1;32m    123\u001b[0m   data \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m--> 124\u001b[0m       (jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mGetAttrKey(name), \u001b[39mgetattr\u001b[39m(x, name))\n\u001b[1;32m    125\u001b[0m       \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m data_fields\n\u001b[1;32m    126\u001b[0m   )\n\u001b[1;32m    127\u001b[0m   \u001b[39mreturn\u001b[39;00m data, meta\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study_cpu.optimize(objective_partial, \n",
    "                n_trials=10-len(study_cpu.trials), \n",
    "                n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = create_dataset(get_data_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(\n",
    "    config=get_best_trial_config(study=study_cpu),\n",
    "    workdir=get_best_trial_workdir(study=study_cpu), # for loading checkpoints \n",
    "    plot_ith_rollout_step=0, # 0 indexed # for this study, we have a 4-step rollout \n",
    "    # dataset,\n",
    "    # preds,\n",
    "    # timestep_duration,\n",
    "    # n_rollout_steps,\n",
    "    #  total_steps,\n",
    "    node=0, # 0-indexed \n",
    "    plot_mode=\"val\", # i.e. \"train\"/\"val\"/\"test\"\n",
    "    datasets=datasets,\n",
    "    plot_all=False, # if false, only plot the first 100 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_vis = remove_bad_trials(study_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study_vis)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'dropout_rate'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'edge_mlp_1_power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'node_mlp_1_power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'optimizer'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['optimizer', 'activation'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['activation', 'node_mlp_1_power'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
