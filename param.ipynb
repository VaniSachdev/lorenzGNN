{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "from tensorflow.python.keras import Model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.metrics import RootMeanSquaredError, MeanSquaredError\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from spektral.models import GCN\n",
    "from spektral.data import MixedLoader\n",
    "from lorenz import lorenzDataset, DEFAULT_TIME_RESOLUTION\n",
    "from plotters import plot_with_predictions, plot_true_vs_pred, plot_data\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THINGS TO TRY \n",
    "- write helper functions! \n",
    "- play with diff sample size (500) - v\n",
    "- input/output day ratio - h \n",
    "- play around with buffer - v\n",
    "- activation layers - h\n",
    "- play with the hidden layers - v \n",
    "- diff data samples / diff lorenz params - h \n",
    "- diff optimizer alg - v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions for hyperparameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_model(train,\n",
    "                        val,\n",
    "                     channels=32,\n",
    "                     activation=\"relu\",\n",
    "                     use_bias=False,\n",
    "                     dropout_rate=0,\n",
    "                     l2_reg=0,\n",
    "                     optimizer='adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     epochs=DEFAULT_EPOCHS): # TODO: add early stopping \n",
    "    # prepare data\n",
    "    train_loader = MixedLoader(dataset=train, batch_size=32, shuffle=False)\n",
    "    val_loader = MixedLoader(dataset=val, batch_size=32, shuffle=False)\n",
    "\n",
    "    # create and train model\n",
    "    GCN_model = GCN(\n",
    "        n_labels=1,\n",
    "        channels=channels,  # i.e. n_hidden layers in each GCNConv layer\n",
    "        activation=activation,\n",
    "        output_activation=None,  # we want regression, i.e. a linear function\n",
    "        use_bias=use_bias,\n",
    "        dropout_rate=dropout_rate,\n",
    "        l2_reg=l2_reg)\n",
    "\n",
    "    GCN_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    history = GCN_model.fit(train_loader.load(),\n",
    "                            steps_per_epoch=train_loader.steps_per_epoch,\n",
    "                            epochs=epochs,\n",
    "                            validation_data = val_loader.load(),\n",
    "                            shuffle=False)\n",
    "    return GCN_model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_results(train, val, GCN_model, history, epochs=DEFAULT_EPOCHS):\n",
    "    # plot training MSE\n",
    "    fig_train_loss, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(history.history['loss'])\n",
    "    ax.set_ylabel('mean squared error')\n",
    "    ax.set_xlabel('epochs')\n",
    "    fig_train_loss.suptitle('model MSE over training epochs')\n",
    "    ax.text(x=0.8 * epochs,\n",
    "            y=1.2 * history.history['loss'][-1],\n",
    "            s=\"final loss: {:.2f}\".format(history.history['loss'][-1]))\n",
    "    ax.set_ylim(0, history.history['loss'][0]*1.1)\n",
    "    ax.legend()\n",
    "\n",
    "    # plot train predictions\n",
    "    fig_train_pred, (ax0,\n",
    "                     ax1) = plot_with_predictions(model=GCN_model,\n",
    "                                                  graph_dataset=train,\n",
    "                                                  Loader=MixedLoader,\n",
    "                                                  batch_size=32,\n",
    "                                                  node=0,\n",
    "                                                  model_name='GCN OOTB train')\n",
    "\n",
    "    # plot val predictions\n",
    "    fig_val_pred, (ax0, ax1) = plot_with_predictions(model=GCN_model,\n",
    "                                                     graph_dataset=val,\n",
    "                                                     Loader=MixedLoader,\n",
    "                                                     batch_size=32,\n",
    "                                                     node=0,\n",
    "                                                     model_name='GCN OOTB val')\n",
    "\n",
    "    # # plot predictions against true value\n",
    "    # fig_true_vs_pred, ax = plot_true_vs_pred(y_true, y_pred)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig_train_loss, fig_train_pred, fig_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/h.lu/spektral/datasets/Lorenz/100000_200_1_100_-300_False_36_8_10_10_1_True_100_42.npz\n",
      "False\n",
      "total steps: 100300\n",
      "starting integration\n"
     ]
    }
   ],
   "source": [
    "# TODO: add logging to see progress\n",
    "\n",
    "# only uncomment each line if testing a non-default parameter\n",
    "dataset = lorenzDataset(\n",
    "    n_samples=100000,\n",
    "    # input_steps=2 * DEFAULT_TIME_RESOLUTION,  # 2 days\n",
    "    # output_delay=1 * DEFAULT_TIME_RESOLUTION,  # 1 day\n",
    "    # output_steps=1,\n",
    "    min_buffer=-3 * DEFAULT_TIME_RESOLUTION,\n",
    "    # rand_buffer=False,\n",
    "    # K=36,\n",
    "    # F=8,\n",
    "    # c=10,\n",
    "    # b=10,\n",
    "    # h=1,\n",
    "    # coupled=True,\n",
    "    # time_resolution=DEFAULT_TIME_RESOLUTION,\n",
    "    # seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:int(0.7 * dataset.n_graphs)]\n",
    "val = dataset[int(0.7 * dataset.n_graphs):int(0.9 * dataset.n_graphs)]\n",
    "test = dataset[int(0.9 * dataset.n_graphs):]\n",
    "\n",
    "# normalize data\n",
    "X1_mean, X1_std, X2_mean, X2_std = train.get_mean_std()\n",
    "\n",
    "train.normalize(X1_mean, X1_std, X2_mean, X2_std)\n",
    "val.normalize(X1_mean, X1_std, X2_mean, X2_std)\n",
    "test.normalize(X1_mean, X1_std, X2_mean, X2_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m----> 2\u001b[0m fig, (ax0, ax1) \u001b[39m=\u001b[39m plot_data(train, val, test, node\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# colors = [\"darkorange\", \"purple\", \"darkcyan\"]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# node = 0\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m#     for i in range(len(leg.legendHandles))\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m# ]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/plotters.py:117\u001b[0m, in \u001b[0;36mplot_data\u001b[0;34m(train, val, test, node)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# plot train, val, and test data\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mplotting train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m fig, (ax0, ax1) \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39;49mplot(node,\n\u001b[1;32m    118\u001b[0m                              fig,\n\u001b[1;32m    119\u001b[0m                              ax0,\n\u001b[1;32m    120\u001b[0m                              ax1,\n\u001b[1;32m    121\u001b[0m                              data_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              color\u001b[39m=\u001b[39;49mcolors[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    123\u001b[0m                              alpha\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m    124\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mplotting val\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    125\u001b[0m fig, (ax0, ax1) \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39mplot(node,\n\u001b[1;32m    126\u001b[0m                            fig,\n\u001b[1;32m    127\u001b[0m                            ax0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m                            color\u001b[39m=\u001b[39mcolors[\u001b[39m1\u001b[39m],\n\u001b[1;32m    131\u001b[0m                            alpha\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/lorenz.py:312\u001b[0m, in \u001b[0;36mlorenzDataset.plot\u001b[0;34m(self, node, fig, ax0, ax1, data_type, color, alpha)\u001b[0m\n\u001b[1;32m    302\u001b[0m     ax0\u001b[39m.\u001b[39mplot(g\u001b[39m.\u001b[39mt_X,\n\u001b[1;32m    303\u001b[0m              g\u001b[39m.\u001b[39mx[node][:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_steps],\n\u001b[1;32m    304\u001b[0m              label\u001b[39m=\u001b[39mdata_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m inputs\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    305\u001b[0m              c\u001b[39m=\u001b[39mcolor,\n\u001b[1;32m    306\u001b[0m              alpha\u001b[39m=\u001b[39malpha)\n\u001b[1;32m    307\u001b[0m     ax1\u001b[39m.\u001b[39mplot(g\u001b[39m.\u001b[39mt_X,\n\u001b[1;32m    308\u001b[0m              g\u001b[39m.\u001b[39mx[node][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_steps:],\n\u001b[1;32m    309\u001b[0m              label\u001b[39m=\u001b[39mdata_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m inputs\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    310\u001b[0m              c\u001b[39m=\u001b[39mcolor,\n\u001b[1;32m    311\u001b[0m              alpha\u001b[39m=\u001b[39malpha)\n\u001b[0;32m--> 312\u001b[0m     ax0\u001b[39m.\u001b[39;49mscatter(g\u001b[39m.\u001b[39;49mt_Y,\n\u001b[1;32m    313\u001b[0m                 g\u001b[39m.\u001b[39;49my[node][:\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_steps],\n\u001b[1;32m    314\u001b[0m                 label\u001b[39m=\u001b[39;49mdata_type \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m labels\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    315\u001b[0m                 s\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m    316\u001b[0m                 c\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    317\u001b[0m                 alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m fig, (ax0, ax1)\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/venv/lib/python3.9/site-packages/matplotlib/__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1422\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1425\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1426\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1427\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4647\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4644\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ymargin \u001b[39m<\u001b[39m \u001b[39m0.05\u001b[39m \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   4645\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_ymargin(\u001b[39m0.05\u001b[39m)\n\u001b[0;32m-> 4647\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_collection(collection)\n\u001b[1;32m   4648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_autoscale_view()\n\u001b[1;32m   4650\u001b[0m \u001b[39mreturn\u001b[39;00m collection\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:2299\u001b[0m, in \u001b[0;36m_AxesBase.add_collection\u001b[0;34m(self, collection, autolim)\u001b[0m\n\u001b[1;32m   2294\u001b[0m     collection\u001b[39m.\u001b[39mset_clip_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch)\n\u001b[1;32m   2296\u001b[0m \u001b[39mif\u001b[39;00m autolim:\n\u001b[1;32m   2297\u001b[0m     \u001b[39m# Make sure viewLim is not stale (mostly to match\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m     \u001b[39m# pre-lazy-autoscale behavior, which is not really better).\u001b[39;00m\n\u001b[0;32m-> 2299\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unstale_viewLim()\n\u001b[1;32m   2300\u001b[0m     datalim \u001b[39m=\u001b[39m collection\u001b[39m.\u001b[39mget_datalim(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransData)\n\u001b[1;32m   2301\u001b[0m     points \u001b[39m=\u001b[39m datalim\u001b[39m.\u001b[39mget_points()\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:810\u001b[0m, in \u001b[0;36m_AxesBase._unstale_viewLim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_axes[name]\u001b[39m.\u001b[39mget_siblings(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m         ax\u001b[39m.\u001b[39m_stale_viewlims[name] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoscale_view(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mscale\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m: scale\n\u001b[1;32m    811\u001b[0m                        \u001b[39mfor\u001b[39;49;00m name, scale \u001b[39min\u001b[39;49;00m need_scale\u001b[39m.\u001b[39;49mitems()})\n",
      "File \u001b[0;32m~/Documents/_code/_research lorenz code/lorenzGNN/venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:2901\u001b[0m, in \u001b[0;36m_AxesBase.autoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         x_stickies \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(np\u001b[39m.\u001b[39mconcatenate([\n\u001b[1;32m   2896\u001b[0m             artist\u001b[39m.\u001b[39msticky_edges\u001b[39m.\u001b[39mx\n\u001b[1;32m   2897\u001b[0m             \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_axes[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget_siblings(\u001b[39mself\u001b[39m)\n\u001b[1;32m   2898\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ax, \u001b[39m\"\u001b[39m\u001b[39m_children\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2899\u001b[0m             \u001b[39mfor\u001b[39;00m artist \u001b[39min\u001b[39;00m ax\u001b[39m.\u001b[39mget_children()]))\n\u001b[1;32m   2900\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ymargin \u001b[39mand\u001b[39;00m scaley \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_autoscaley_on():\n\u001b[0;32m-> 2901\u001b[0m         y_stickies \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(np\u001b[39m.\u001b[39;49mconcatenate([\n\u001b[1;32m   2902\u001b[0m             artist\u001b[39m.\u001b[39;49msticky_edges\u001b[39m.\u001b[39;49my\n\u001b[1;32m   2903\u001b[0m             \u001b[39mfor\u001b[39;49;00m ax \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shared_axes[\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mget_siblings(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   2904\u001b[0m             \u001b[39mif\u001b[39;49;00m \u001b[39mhasattr\u001b[39;49m(ax, \u001b[39m\"\u001b[39;49m\u001b[39m_children\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2905\u001b[0m             \u001b[39mfor\u001b[39;49;00m artist \u001b[39min\u001b[39;49;00m ax\u001b[39m.\u001b[39;49mget_children()]))\n\u001b[1;32m   2906\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xscale() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   2907\u001b[0m     x_stickies \u001b[39m=\u001b[39m x_stickies[x_stickies \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "fig, (ax0, ax1) = plot_data(train, val, test, node=0)\n",
    "# colors = [\"darkorange\", \"purple\", \"darkcyan\"]\n",
    "# node = 0\n",
    "\n",
    "# # set up plot\n",
    "# fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(20, 8))\n",
    "\n",
    "# fig.suptitle(\"sampled time series after reshaping\", size=28)\n",
    "# ax0.set_title(\"X1 (i.e. atmospheric variable) for node {}\".format(node),\n",
    "#               size=20)\n",
    "# ax1.set_title(\"X2 (i.e. oceanic variable) for node {}\".format(node), size=20)\n",
    "# plt.xlabel('time (days)', size=16)\n",
    "\n",
    "# # plot train, val, and test data\n",
    "# print('plotting train')\n",
    "# fig, (ax0, ax1) = train.plot(node,\n",
    "#                              fig,\n",
    "#                              ax0,\n",
    "#                              ax1,\n",
    "#                              data_type='train',\n",
    "#                              color=colors[0], alpha=0.2)\n",
    "# print('plotting val')\n",
    "# fig, (ax0, ax1) = val.plot(node,\n",
    "#                            fig,\n",
    "#                            ax0,\n",
    "#                            ax1,\n",
    "#                            data_type='val',\n",
    "#                            color=colors[1], alpha=0.2)\n",
    "# print('plotting test')\n",
    "# fig, (ax0, ax1) = test.plot(node,\n",
    "#                             fig,\n",
    "#                             ax0,\n",
    "#                             ax1,\n",
    "#                             data_type='test',\n",
    "#                             color=colors[2], alpha=0.2)\n",
    "\n",
    "# ax0.set_xlim(train[0].t_X[0], test[-1].t_Y[-1])\n",
    "# ax1.set_xlim(train[0].t_X[0], test[-1].t_Y[-1])\n",
    "\n",
    "# print('editing legend')\n",
    "# # create legend\n",
    "# ax0.legend()\n",
    "# ax0.legend(handles=ax0.get_legend().legendHandles[0:6])\n",
    "# leg = ax0.get_legend()\n",
    "# [\n",
    "#     leg.legendHandles[i].set_color(colors[i // 2])\n",
    "#     for i in range(len(leg.legendHandles))\n",
    "# ]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = make_train_model(train, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig_train_loss, fig_train_pred, fig_val_pred \u001b[39m=\u001b[39m plot_model_results(\n\u001b[0;32m----> 2\u001b[0m     train[:\u001b[39m1000\u001b[39m], val[:\u001b[39m1000\u001b[39m], model, history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "fig_train_loss, fig_train_pred, fig_val_pred = plot_model_results(\n",
    "    train[:1000], val[:1000], model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "side note: why are the outputs different every time? is there another seed we need to set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91babaf3c1d56d103efe045a1206cf7a774c89fdf942e1060ceffb69eaea3c50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
