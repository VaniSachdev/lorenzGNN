{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts\n",
    "from utils.jraph_training import rollout_loss, train_step, train_step_fn, evaluate_model, train_and_evaluate, create_dataset #, rollout_loss_batched, \n",
    "from utils.jraph_models import MLPBlock\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from flax_gnn_example.configs import mlpblock_test\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test single rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)\n"
     ]
    }
   ],
   "source": [
    "def get_sample_data(seed=42):\n",
    "    sample_dataset = get_lorenz_graph_tuples(\n",
    "        n_samples=10,\n",
    "        input_steps=3,\n",
    "        output_delay=0,\n",
    "        output_steps=2,\n",
    "        timestep_duration=1,\n",
    "        sample_buffer=1,\n",
    "        time_resolution=100,\n",
    "        init_buffer_samples=0,\n",
    "        train_pct=.2,\n",
    "        val_pct=0.4,\n",
    "        test_pct=0.4,\n",
    "        K=36,\n",
    "        F=8,\n",
    "        c=10,\n",
    "        b=10,\n",
    "        h=1,\n",
    "        seed=seed,\n",
    "        normalize=False)\n",
    "    # input_window = sample_dataset['train']['input'][0]\n",
    "    # target_window = sample_dataset['train']['targets'][0]\n",
    "    return sample_dataset \n",
    "\n",
    "sample_dataset = get_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=mlpblock_test.get_config()\n",
    "sample_dataset = create_dataset(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_input_window = sample_dataset['train']['inputs'][0]\n",
    "sample_target_window = sample_dataset['train']['targets'][0]\n",
    "\n",
    "sample_input_graph = sample_input_window[0]\n",
    "sample_target_graph = sample_target_window[0]\n",
    "\n",
    "sample_input_batch = sample_dataset['train']['inputs']\n",
    "sample_target_batch = sample_dataset['train']['targets']\n",
    "\n",
    "print_graph_fts(sample_input_graph)\n",
    "print_graph_fts(sample_target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "[6]\n",
      "(30, 1)\n",
      "[30]\n",
      "(30,)\n",
      "6\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(sample_input_graph.nodes.shape)\n",
    "print(sample_input_graph.n_node)\n",
    "print(sample_input_graph.edges.shape)\n",
    "print(sample_input_graph.n_edge)\n",
    "print(sample_input_graph.receivers.shape)\n",
    "print(sample_input_graph.n_node[1])\n",
    "print(sample_input_graph.n_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_graph\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--Call--\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/lorenzvenv/lib/python3.9/site-packages/jraph/_src/models.py\u001b[0m(142)\u001b[0;36m_ApplyGraphNet\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    140 \u001b[0;31m                      ' supplied.'))\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 142 \u001b[0;31m  \u001b[0;32mdef\u001b[0m \u001b[0m_ApplyGraphNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m    \"\"\"Applies a configured GraphNetwork to a graph.\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# set up state \n",
    "\n",
    "hidden_layer_features = {'edge': [16, 8], \n",
    "                        'node': [32, 2], 'global': None}\n",
    "model = MLPBlock(edge_features=hidden_layer_features['edge'],\n",
    "                node_features=hidden_layer_features['node'],\n",
    "                global_features=hidden_layer_features['global'])\n",
    "\n",
    "# set up params\n",
    "# init_graphs = test_input_graph\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "params = jax.jit(model.init)(init_rng, sample_input_window)\n",
    "\n",
    "# set up optimizer (needed for the state even if we aren't training)\n",
    "learning_rate = 0.001  # default learning rate for adam in keras\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "\n",
    "# set up state object, which helps us keep track of the model, params, and optimizer\n",
    "state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                        params=params,\n",
    "                                        tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_graph\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n",
      "input_graph\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# test single rollout \n",
    "avg_loss, pred_nodes = rollout_loss(\n",
    "    state=state, \n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window,\n",
    "    rngs=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0748875\n",
      "<class 'list'>\n",
      "2\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(6, 2)\n",
      "[[0.55302817 1.4878951 ]\n",
      " [0.55302817 1.4880304 ]\n",
      " [0.55302817 1.4881315 ]\n",
      " [0.55302817 1.4880161 ]\n",
      " [0.56065965 1.4864204 ]\n",
      " [0.55302817 1.4879614 ]]\n",
      "[[0.4858688  1.202163  ]\n",
      " [0.5044668  1.2232045 ]\n",
      " [0.48546994 1.202471  ]\n",
      " [0.4850514  1.2159793 ]\n",
      " [0.47401622 1.2174321 ]\n",
      " [0.00990715 1.2830077 ]]\n"
     ]
    }
   ],
   "source": [
    "print(avg_loss)\n",
    "print(type(pred_nodes))\n",
    "print(len(pred_nodes))\n",
    "\n",
    "print(type(pred_nodes[0]))\n",
    "print(pred_nodes[0].shape)\n",
    "print(pred_nodes[0])\n",
    "print(pred_nodes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test rollout loss batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we're getting an issue that i don't know how to immediately fix and batching isn't our top priority right now so i'm going to leave this loose end hanging. TODO later \n",
    "\n",
    "the problem: when we treat a list of GraphsTuples as a jax pytree, for some reason, it treats each attribute of the named tuple as a leaf in the pytree?? so we have n_windows * n_elements in the graphtuple number of leaves. \n",
    "\n",
    "what we'd need to do to fix it is to treat each GraphsTuple as a unique leaf. not sure how to set this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(sample_input_batch)\n",
    "# print_graph_fts(sample_input_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(6, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(30,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "jax.tree_util.tree_leaves(sample_input_batch)\n",
    "for leaf in jax.tree_util.tree_leaves(sample_input_batch):\n",
    "    print(type(leaf))\n",
    "    print(leaf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_avg_loss, batch_pred_nodes = rollout_loss_batched(state, \n",
    "#                  sample_input_batch,\n",
    "#                  sample_target_batch,\n",
    "#                  None,\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['params'])\n",
      "dict_keys(['MLP_0', 'MLP_1'])\n",
      "dict_keys(['Dense_0', 'Dense_1'])\n",
      "dict_keys(['bias', 'kernel'])\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(16,)\n",
      "(6, 16)\n",
      "(8,)\n",
      "(16, 8)\n",
      "(32,)\n",
      "(19, 32)\n",
      "(2,)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "# check number of params\n",
    "print(type(params))\n",
    "print(params.keys())\n",
    "print(params['params'].keys())\n",
    "print(params['params']['MLP_0'].keys())\n",
    "print(params['params']['MLP_0']['Dense_0'].keys())\n",
    "print(type(params['params']['MLP_0']['Dense_0']['bias']))\n",
    "print(params['params']['MLP_0']['Dense_0']['bias'].shape)\n",
    "print(params['params']['MLP_0']['Dense_0']['kernel'].shape)\n",
    "print(params['params']['MLP_0']['Dense_1']['bias'].shape)\n",
    "print(params['params']['MLP_0']['Dense_1']['kernel'].shape)\n",
    "print(params['params']['MLP_1']['Dense_0']['bias'].shape)\n",
    "print(params['params']['MLP_1']['Dense_0']['kernel'].shape)\n",
    "print(params['params']['MLP_1']['Dense_1']['bias'].shape)\n",
    "print(params['params']['MLP_1']['Dense_1']['kernel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_graph\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n",
      "input_graph\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: 6\n",
      "Number of edges: 30\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# run train step\n",
    "new_state, metrics_update, pred_nodes = train_step_fn(\n",
    "    state=state,\n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window,\n",
    "    rngs={'dropout': rng}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try fixing jit batching issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jraph\n",
    "# batch = jax.jit(jraph.batch)(sample_input_batch)\n",
    "# print_graph_fts(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(6, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flax_gnn_example.train import unbatch_i\n",
    "# first_graph = jax.jit(unbatch_i)(sample_input_window, 0)\n",
    "# first_window = jraph.unbatch(sample_input_window)\n",
    "def func_with_list(l):\n",
    "   res = 0\n",
    "   for i in l:\n",
    "      res += i\n",
    "   return res\n",
    "\n",
    "jax.jit(func_with_list)([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "give up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test evaluate_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_graph\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n",
      "input_graph\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 1)\n",
      "Global features shape: (1, 1)\n",
      "> \u001b[0;32m/Users/h.lu/Documents/_code/_research lorenz code/lorenzGNN/utils/jraph_models.py\u001b[0m(112)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    110 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    111 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 112 \u001b[0;31m        \u001b[0mprocessed_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    113 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_graphs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m        \u001b[0mprint_graph_fts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "processed_graphs\n",
      "Number of nodes: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Number of edges: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Node features shape: (6, 2)\n",
      "Edge features shape: (30, 8)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = evaluate_model(\n",
    "    state=state,\n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    datasets=sample_dataset,\n",
    "    # first key = train/test/val, second key = input/target \n",
    "    splits=['val', 'test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val': EvalMetrics(_reduction_counter=_ReductionCounter(value=Array(4, dtype=int32, weak_type=True)), loss=Metric.from_output.<locals>.FromOutput(total=Array(685.5943, dtype=float32), count=Array(4., dtype=float32))), 'test': EvalMetrics(_reduction_counter=_ReductionCounter(value=Array(4, dtype=int32, weak_type=True)), loss=Metric.from_output.<locals>.FromOutput(total=Array(597.77374, dtype=float32), count=Array(4., dtype=float32)))}\n",
      "Metric.from_output.<locals>.FromOutput(total=Array(685.5943, dtype=float32), count=Array(4., dtype=float32))\n",
      "685.5943\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(eval_metrics)\n",
    "print(eval_metrics['val'].loss)\n",
    "print(eval_metrics['val'].loss.total)\n",
    "print(eval_metrics['val'].loss.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state.step)\n",
    "state.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test full training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO PICK UP HERE AND DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Hyperparameters: {'F': 8, 'K': 6, 'add_self_loops': True, 'add_undirected_edges': True, 'add_virtual_node': True, 'b': 10, 'batch_size': 3, 'c': 10, 'checkpoint_every_epochs': 1, 'checkpoint_every_steps': 2, 'dropout_rate': 0.1, 'epochs': 4, 'eval_every_epochs': 1, 'eval_every_steps': 1, 'h': 1, 'init_buffer_samples': 0, 'input_steps': 3, 'layer_norm': False, 'learning_rate': 0.001, 'log_every_epochs': 1, 'log_every_steps': 2, 'model': 'MLPBlock', 'n_samples': 10, 'normalize': True, 'optimizer': 'adam', 'output_delay': 0, 'output_steps': 2, 'sample_buffer': 1, 'seed': 42, 'skip_connections': False, 'test_pct': 0.4, 'time_resolution': 100, 'timestep_duration': 1, 'train_pct': 0.2, 'val_pct': 0.4}\n",
      "INFO:absl:Obtaining datasets.\n",
      "INFO:absl:Initializing network.\n",
      "INFO:absl:\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "| Name                        | Shape    | Size | Mean    | Std   |\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "| params/MLP_0/Dense_0/bias   | (4,)     | 4    | 0.0     | 0.0   |\n",
      "| params/MLP_0/Dense_0/kernel | (6, 4)   | 24   | -0.058  | 0.351 |\n",
      "| params/MLP_0/Dense_1/bias   | (8,)     | 8    | 0.0     | 0.0   |\n",
      "| params/MLP_0/Dense_1/kernel | (4, 8)   | 32   | -0.117  | 0.526 |\n",
      "| params/MLP_1/Dense_0/bias   | (32,)    | 32   | 0.0     | 0.0   |\n",
      "| params/MLP_1/Dense_0/kernel | (19, 32) | 608  | -0.0168 | 0.222 |\n",
      "| params/MLP_1/Dense_1/bias   | (2,)     | 2    | 0.0     | 0.0   |\n",
      "| params/MLP_1/Dense_1/kernel | (32, 2)  | 64   | 0.0125  | 0.175 |\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "Total: 774\n",
      "INFO:absl:Checkpoint.restore_or_initialize() ...\n",
      "INFO:absl:No checkpoint specified. Restore the latest checkpoint.\n",
      "INFO:absl:Checkpoint None does not exist.\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:Checkpoint.save() finished after 0.01s.\n",
      "INFO:absl:Checkpoint.restore_or_initialize() finished after 0.01s.\n",
      "INFO:absl:Starting training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:[0] train_loss=0.26761993765830994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:[0] val_loss=394.91632080078125\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[0] test_loss=499.5340576171875\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n",
      "INFO:absl:[1] val_loss=394.67730712890625\n",
      "INFO:absl:[1] test_loss=496.6314392089844\n",
      "INFO:absl:[2] train_loss=4.852296352386475\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[2] val_loss=394.0526428222656\n",
      "INFO:absl:[2] test_loss=493.9013671875\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n",
      "INFO:absl:[3] val_loss=393.9186096191406\n",
      "INFO:absl:[3] test_loss=491.12677001953125\n",
      "INFO:absl:[4] train_loss=4.80951452255249\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[4] val_loss=393.5780334472656\n",
      "INFO:absl:[4] test_loss=488.6341247558594\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n",
      "INFO:absl:[5] val_loss=393.5848083496094\n",
      "INFO:absl:[5] test_loss=486.771728515625\n",
      "INFO:absl:[6] train_loss=4.766618728637695\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[6] val_loss=393.40545654296875\n",
      "INFO:absl:[6] test_loss=485.63525390625\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n",
      "INFO:absl:[7] train_loss=9.252385139465332\n",
      "INFO:absl:[7] val_loss=393.4309997558594\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[7] test_loss=484.7817687988281\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n",
      "epoch 1\n",
      "step 2\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n",
      "step 3\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n",
      "epoch 2\n",
      "step 4\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n",
      "step 5\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) False\n",
      "\n",
      "epoch 3\n",
      "step 6\n",
      "is_last_step False\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) True\n",
      "\n",
      "step 7\n",
      "is_last_step True\n",
      "num_train_steps 8\n",
      "(epoch == config.epochs - 1) True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_config = mlpblock_test.get_config()\n",
    "workdir=f\"tests/outputs/train_testing_dir_{datetime.now()}\"\n",
    "\n",
    "trained_state = train_and_evaluate(config=mlp_config, workdir=workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'flax.training.train_state.TrainState'>\n",
      "8\n",
      "(6, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(trained_state))\n",
    "print(trained_state.step)\n",
    "print(trained_state.params['params']['MLP_0']['Dense_0']['kernel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
