{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts\n",
    "from utils.jraph_training import rollout_loss, train_step, train_step_fn, evaluate_model, train_and_evaluate, create_dataset #, rollout_loss_batched, \n",
    "from utils.jraph_models import MLPBlock\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from flax_gnn_example.configs import mlpblock_test\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test single rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data(seed=42):\n",
    "    sample_dataset = get_lorenz_graph_tuples(\n",
    "        n_samples=10,\n",
    "        input_steps=3,\n",
    "        output_delay=0,\n",
    "        output_steps=2,\n",
    "        timestep_duration=1,\n",
    "        sample_buffer=1,\n",
    "        time_resolution=100,\n",
    "        init_buffer_samples=0,\n",
    "        train_pct=.2,\n",
    "        val_pct=0.4,\n",
    "        test_pct=0.4,\n",
    "        K=36,\n",
    "        F=8,\n",
    "        c=10,\n",
    "        b=10,\n",
    "        h=1,\n",
    "        seed=seed,\n",
    "        normalize=False)\n",
    "    # input_window = sample_dataset['train']['input'][0]\n",
    "    # target_window = sample_dataset['train']['targets'][0]\n",
    "    return sample_dataset \n",
    "\n",
    "sample_dataset = get_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=mlpblock_test.get_config()\n",
    "sample_dataset = create_dataset(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 36\n",
      "Number of edges: 180\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (1296, 1)\n",
      "Global features shape: (1, 1)\n",
      "Number of nodes: 36\n",
      "Number of edges: 180\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (1296, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_input_window = sample_dataset['train']['inputs'][0]\n",
    "sample_target_window = sample_dataset['train']['targets'][0]\n",
    "\n",
    "sample_input_graph = sample_input_window[0]\n",
    "sample_target_graph = sample_target_window[0]\n",
    "\n",
    "sample_input_batch = sample_dataset['train']['inputs']\n",
    "sample_target_batch = sample_dataset['train']['targets']\n",
    "\n",
    "print_graph_fts(sample_input_graph)\n",
    "print_graph_fts(sample_target_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 2)\n",
      "[36]\n",
      "(1296, 1)\n",
      "[180]\n",
      "(1296,)\n",
      "36\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(sample_input_graph.nodes.shape)\n",
    "print(sample_input_graph.n_node)\n",
    "print(sample_input_graph.edges.shape)\n",
    "print(sample_input_graph.n_edge)\n",
    "print(sample_input_graph.receivers.shape)\n",
    "print(sample_input_graph.n_node[1])\n",
    "print(sample_input_graph.n_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 2)\n",
      "(1296, 1)\n",
      "(1, 1)\n",
      "(1296,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([ 0,  1,  2, ..., 33, 34, 35], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sample_input_window[0].nodes.shape)\n",
    "print(sample_input_window[0].edges.shape)\n",
    "print(sample_input_window[0].globals.shape)\n",
    "print(sample_input_window[0].receivers.shape)\n",
    "sample_input_window[0].receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up state \n",
    "\n",
    "hidden_layer_features = {'edge': [16, 8], \n",
    "                        'node': [32, 2], 'global': None}\n",
    "model = MLPBlock(edge_features=hidden_layer_features['edge'],\n",
    "                node_features=hidden_layer_features['node'],\n",
    "                global_features=hidden_layer_features['global'])\n",
    "\n",
    "# set up params\n",
    "# init_graphs = test_input_graph\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "params = jax.jit(model.init)(init_rng, sample_input_window)\n",
    "\n",
    "# set up optimizer (needed for the state even if we aren't training)\n",
    "learning_rate = 0.001  # default learning rate for adam in keras\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "\n",
    "# set up state object, which helps us keep track of the model, params, and optimizer\n",
    "state = train_state.TrainState.create(apply_fn=model.apply,\n",
    "                                        params=params,\n",
    "                                        tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test single rollout \n",
    "avg_loss, pred_nodes = rollout_loss(\n",
    "    state=state, \n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window,\n",
    "    rngs=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758.22\n",
      "<class 'list'>\n",
      "2\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(36, 2)\n",
      "[[ 0.6568187  58.017986  ]\n",
      " [ 0.6568187  58.017982  ]\n",
      " [ 0.6568187  58.017986  ]\n",
      " [ 0.6568187  58.017742  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.01782   ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.017826  ]\n",
      " [ 0.6568187  58.017826  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.01777   ]\n",
      " [ 0.6568187  58.017757  ]\n",
      " [ 0.6568187  58.018368  ]\n",
      " [ 0.6568187  58.01841   ]\n",
      " [ 0.6568187  58.018414  ]\n",
      " [ 0.66054416 58.000698  ]\n",
      " [ 0.6568187  58.01778   ]\n",
      " [ 0.6568187  58.017986  ]\n",
      " [ 0.6568187  58.017982  ]\n",
      " [ 0.6568187  58.017986  ]\n",
      " [ 0.6568187  58.017742  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.01782   ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.017826  ]\n",
      " [ 0.6568187  58.017826  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.017822  ]\n",
      " [ 0.6568187  58.01777   ]\n",
      " [ 0.6568187  58.017757  ]\n",
      " [ 0.6568187  58.018368  ]\n",
      " [ 0.6568187  58.01841   ]\n",
      " [ 0.6568187  58.018414  ]\n",
      " [ 0.6568187  58.018303  ]\n",
      " [ 0.6568187  58.01778   ]]\n",
      "[[ 0.51209605 60.464092  ]\n",
      " [ 0.5512201  60.26259   ]\n",
      " [ 0.50983524 60.448864  ]\n",
      " [ 0.5088043  60.44791   ]\n",
      " [ 0.5099063  60.443146  ]\n",
      " [ 0.50992763 60.444233  ]\n",
      " [ 0.5099063  60.44553   ]\n",
      " [ 0.5098992  60.447746  ]\n",
      " [ 0.5099063  60.449913  ]\n",
      " [ 0.5099063  60.452072  ]\n",
      " [ 0.5099063  60.4543    ]\n",
      " [ 0.5099063  60.4565    ]\n",
      " [ 0.5099063  60.45836   ]\n",
      " [ 0.5099063  60.460533  ]\n",
      " [ 0.50991344 60.476112  ]\n",
      " [ 0.5101978  60.364803  ]\n",
      " [ 0.5135962  60.27992   ]\n",
      " [ 0.50987786 60.301853  ]\n",
      " [ 0.50960773 60.468952  ]\n",
      " [ 0.5099063  60.456017  ]\n",
      " [ 0.50991344 60.448315  ]\n",
      " [ 0.5099063  60.4427    ]\n",
      " [ 0.5098992  60.44317   ]\n",
      " [ 0.5099063  60.444324  ]\n",
      " [ 0.5099063  60.44553   ]\n",
      " [ 0.5099063  60.447704  ]\n",
      " [ 0.5099063  60.449913  ]\n",
      " [ 0.5099063  60.452126  ]\n",
      " [ 0.5099063  60.45432   ]\n",
      " [ 0.5099063  60.45616   ]\n",
      " [ 0.5099063  60.458244  ]\n",
      " [ 0.5099063  60.4622    ]\n",
      " [ 0.50987786 60.476757  ]\n",
      " [ 0.5087972  60.36404   ]\n",
      " [ 0.46858543 60.4888    ]\n",
      " [-0.5240544  65.73921   ]]\n"
     ]
    }
   ],
   "source": [
    "print(avg_loss)\n",
    "print(type(pred_nodes))\n",
    "print(len(pred_nodes))\n",
    "\n",
    "print(type(pred_nodes[0]))\n",
    "print(pred_nodes[0].shape)\n",
    "print(pred_nodes[0])\n",
    "print(pred_nodes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test rollout loss batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we're getting an issue that i don't know how to immediately fix and batching isn't our top priority right now so i'm going to leave this loose end hanging. TODO later \n",
    "\n",
    "the problem: when we treat a list of GraphsTuples as a jax pytree, for some reason, it treats each attribute of the named tuple as a leaf in the pytree?? so we have n_windows * n_elements in the graphtuple number of leaves. \n",
    "\n",
    "what we'd need to do to fix it is to treat each GraphsTuple as a unique leaf. not sure how to set this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(sample_input_batch)\n",
    "# print_graph_fts(sample_input_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(36, 2)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1296,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1, 1)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "jax.tree_util.tree_leaves(sample_input_batch)\n",
    "for leaf in jax.tree_util.tree_leaves(sample_input_batch):\n",
    "    print(type(leaf))\n",
    "    print(leaf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_avg_loss, batch_pred_nodes = rollout_loss_batched(state, \n",
    "#                  sample_input_batch,\n",
    "#                  sample_target_batch,\n",
    "#                  None,\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['params'])\n",
      "dict_keys(['MLP_0', 'MLP_1'])\n",
      "dict_keys(['Dense_0', 'Dense_1'])\n",
      "dict_keys(['bias', 'kernel'])\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "(16,)\n",
      "(6, 16)\n",
      "(8,)\n",
      "(16, 8)\n",
      "(32,)\n",
      "(19, 32)\n",
      "(2,)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "# check number of params\n",
    "print(type(params))\n",
    "print(params.keys())\n",
    "print(params['params'].keys())\n",
    "print(params['params']['MLP_0'].keys())\n",
    "print(params['params']['MLP_0']['Dense_0'].keys())\n",
    "print(type(params['params']['MLP_0']['Dense_0']['bias']))\n",
    "print(params['params']['MLP_0']['Dense_0']['bias'].shape)\n",
    "print(params['params']['MLP_0']['Dense_0']['kernel'].shape)\n",
    "print(params['params']['MLP_0']['Dense_1']['bias'].shape)\n",
    "print(params['params']['MLP_0']['Dense_1']['kernel'].shape)\n",
    "print(params['params']['MLP_1']['Dense_0']['bias'].shape)\n",
    "print(params['params']['MLP_1']['Dense_0']['kernel'].shape)\n",
    "print(params['params']['MLP_1']['Dense_1']['bias'].shape)\n",
    "print(params['params']['MLP_1']['Dense_1']['kernel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train step\n",
    "new_state, metrics_update, pred_nodes = train_step_fn(\n",
    "    state=state,\n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window,\n",
    "    rngs={'dropout': rng}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try fixing jit batching issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jraph\n",
    "# batch = jax.jit(jraph.batch)(sample_input_batch)\n",
    "# print_graph_fts(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(6, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flax_gnn_example.train import unbatch_i\n",
    "# first_graph = jax.jit(unbatch_i)(sample_input_window, 0)\n",
    "# first_window = jraph.unbatch(sample_input_window)\n",
    "def func_with_list(l):\n",
    "   res = 0\n",
    "   for i in l:\n",
    "      res += i\n",
    "   return res\n",
    "\n",
    "jax.jit(func_with_list)([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "give up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test evaluate_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = evaluate_model(\n",
    "    state=state,\n",
    "    n_rollout_steps=len(sample_target_window),\n",
    "    datasets=sample_dataset,\n",
    "    # first key = train/test/val, second key = input/target \n",
    "    splits=['val', 'test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val': EvalMetrics(_reduction_counter=_ReductionCounter(value=Array(4, dtype=int32, weak_type=True)), loss=Metric.from_output.<locals>.FromOutput(total=Array(23624.05, dtype=float32), count=Array(4., dtype=float32))), 'test': EvalMetrics(_reduction_counter=_ReductionCounter(value=Array(4, dtype=int32, weak_type=True)), loss=Metric.from_output.<locals>.FromOutput(total=Array(41627.9, dtype=float32), count=Array(4., dtype=float32)))}\n",
      "Metric.from_output.<locals>.FromOutput(total=Array(23624.05, dtype=float32), count=Array(4., dtype=float32))\n",
      "23624.05\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(eval_metrics)\n",
    "print(eval_metrics['val'].loss)\n",
    "print(eval_metrics['val'].loss.total)\n",
    "print(eval_metrics['val'].loss.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state.step)\n",
    "state.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test full training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO PICK UP HERE AND DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Obtaining datasets.\n",
      "INFO:absl:Hyperparameters: {'F': 8, 'K': 36, 'add_self_loops': True, 'add_undirected_edges': True, 'add_virtual_node': True, 'b': 10, 'batch_size': 3, 'c': 10, 'checkpoint_every_epochs': 1, 'dropout_rate': 0.1, 'edge_features': (4, 8), 'epochs': 4, 'eval_every_epochs': 1, 'global_features': None, 'h': 1, 'init_buffer_samples': 0, 'input_steps': 3, 'layer_norm': False, 'learning_rate': 0.001, 'log_every_epochs': 1, 'model': 'MLPBlock', 'n_samples': 10, 'node_features': (32, 2), 'normalize': True, 'optimizer': 'adam', 'output_delay': 0, 'output_steps': 2, 'sample_buffer': 1, 'seed': 42, 'skip_connections': False, 'test_pct': 0.4, 'time_resolution': 100, 'timestep_duration': 1, 'train_pct': 0.2, 'val_pct': 0.4}\n",
      "INFO:absl:Initializing network.\n",
      "INFO:absl:\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "| Name                        | Shape    | Size | Mean    | Std   |\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "| params/MLP_0/Dense_0/bias   | (4,)     | 4    | 0.0     | 0.0   |\n",
      "| params/MLP_0/Dense_0/kernel | (6, 4)   | 24   | -0.058  | 0.351 |\n",
      "| params/MLP_0/Dense_1/bias   | (8,)     | 8    | 0.0     | 0.0   |\n",
      "| params/MLP_0/Dense_1/kernel | (4, 8)   | 32   | -0.117  | 0.526 |\n",
      "| params/MLP_1/Dense_0/bias   | (32,)    | 32   | 0.0     | 0.0   |\n",
      "| params/MLP_1/Dense_0/kernel | (19, 32) | 608  | -0.0168 | 0.222 |\n",
      "| params/MLP_1/Dense_1/bias   | (2,)     | 2    | 0.0     | 0.0   |\n",
      "| params/MLP_1/Dense_1/kernel | (32, 2)  | 64   | 0.0125  | 0.175 |\n",
      "+-----------------------------+----------+------+---------+-------+\n",
      "Total: 774\n",
      "INFO:absl:Checkpoint.restore_or_initialize() ...\n",
      "INFO:absl:No checkpoint specified. Restore the latest checkpoint.\n",
      "INFO:absl:Checkpoint None does not exist.\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:Checkpoint.save() finished after 0.01s.\n",
      "INFO:absl:Checkpoint.restore_or_initialize() finished after 0.02s.\n",
      "INFO:absl:Starting training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Finished training step 0.\n",
      "INFO:absl:Finished training step 1.\n",
      "INFO:absl:[2] train_loss=13.500608444213867\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[2] val_loss=935.670166015625\n",
      "INFO:absl:[2] test_loss=1591.06005859375\n",
      "INFO:absl:Checkpoint.save() finished after 0.04s.\n",
      "INFO:absl:[4] train_loss=17.09326934814453\n",
      "INFO:absl:[4] val_loss=872.2733764648438\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[4] test_loss=1466.304931640625\n",
      "INFO:absl:Checkpoint.save() finished after 0.03s.\n",
      "INFO:absl:[6] train_loss=13.328892707824707\n",
      "INFO:absl:[6] val_loss=811.263916015625\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[6] test_loss=1344.5447998046875\n",
      "INFO:absl:Checkpoint.save() finished after 0.02s.\n",
      "INFO:absl:[8] train_loss=12.038654327392578\n",
      "INFO:absl:Checkpoint.save() ...\n",
      "INFO:absl:[8] val_loss=754.405029296875\n",
      "INFO:absl:[8] test_loss=1231.849609375\n",
      "INFO:absl:Checkpoint.save() finished after 0.03s.\n"
     ]
    }
   ],
   "source": [
    "mlp_config = mlpblock_test.get_config()\n",
    "workdir=f\"tests/outputs/train_testing_dir_{datetime.now()}\"\n",
    "\n",
    "trained_state, train_metrics, eval_metrics_dict = train_and_evaluate(config=mlp_config, workdir=workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'flax.training.train_state.TrainState'>\n",
      "8\n",
      "(6, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(trained_state))\n",
    "print(trained_state.step)\n",
    "print(trained_state.params['params']['MLP_0']['Dense_0']['kernel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3017.62, dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics_dict['val'].loss.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
