{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some sample data to test out different metric implementations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_training import create_dataset, create_model, create_optimizer\n",
    "from utils.jraph_data import print_graph_fts\n",
    "from flax.training import train_state\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jscipy \n",
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get some sample data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function returns a config for a small dataset, which we can then use to create the actual dataset. \n",
    "\n",
    "(Don't worry too much about what is happening here, I just pasted it here for transparency. The key points are that we will get a dataset with 100 total samples – 70 in train, 20 in val, and 10 in test. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.n_samples=100\n",
    "    config.input_steps=1\n",
    "    config.output_delay=8 # predict 24 hrs into the future \n",
    "    config.output_steps=4\n",
    "    config.time_resolution=120 # the number of \n",
    "                # raw data points generated per time unit, equivalent to the \n",
    "                # number of data points generated per 5 days in the simulation\n",
    "    config.timestep_duration=3 # equivalent to 3 hours\n",
    "    # note a 3 hour timestep resolution would be 5*24/3=40\n",
    "    # if the time_resolution is 120, then a sampling frequency of 3 would achieve a 3 hour timestep \n",
    "    config.sample_buffer = (\n",
    "        -1 * (\n",
    "            config.input_steps + \n",
    "            config.output_delay + \n",
    "            config.output_steps - 1)\n",
    "        ) \n",
    "        # number of timesteps strictly between the end of one full sample and the start of the next sample\n",
    "        # we want a negative buffer so that our sample input are continuous (i.e. the first sample would overlap a bit with consecutive samples) \n",
    "    config.init_buffer_samples=100\n",
    "    config.train_pct=0.7\n",
    "    config.val_pct=0.2\n",
    "    config.test_pct=0.1\n",
    "    config.K=36\n",
    "    config.F=8\n",
    "    config.c=10\n",
    "    config.b=10\n",
    "    config.h=1\n",
    "    config.seed=42\n",
    "    config.normalize=True\n",
    "    config.fully_connected_edges=False\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = get_data_config()\n",
    "datasets = create_dataset(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset is a nested dictionary with the following structure: \n",
    "{\n",
    "'train': {\n",
    "    'inputs': list of windows of graphtuples\n",
    "    'targets': list of windows of graphtuples},\n",
    "'val': {\n",
    "    'inputs': list of windows of graphtuples,\n",
    "    'targets': list of windows of graphtuples},\n",
    "'test': {\n",
    "    'inputs': list of windows of graphtuples,\n",
    "    'targets': list of windows of graphtuples},\n",
    "}\n",
    "\n",
    "A \"window\" is a time series of graphs, here representing either the input sequence or output sequence of data. This are represented as lists, so really each value in the nested dict is a list of list of GraphsTuple objects. \n",
    "\n",
    "Below we demonstrate how to navigate the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test'])\n",
      "dict_keys(['inputs', 'targets'])\n",
      "type(input_train_data) <class 'list'>\n",
      "type(first_input_window) <class 'list'>\n",
      "type(first_input_graph) <class 'jraph._src.graph.GraphsTuple'>\n"
     ]
    }
   ],
   "source": [
    "print(datasets.keys())\n",
    "print(datasets['train'].keys())\n",
    "\n",
    "input_train_data = datasets['train']['inputs']\n",
    "first_input_window = input_train_data[0]\n",
    "first_input_graph = first_input_window[0]\n",
    "first_target_graph = datasets['train']['targets'][0][0]\n",
    "\n",
    "print(\"type(input_train_data)\", type(input_train_data))\n",
    "print(\"type(first_input_window)\", type(first_input_window))\n",
    "print(\"type(first_input_graph)\", type(first_input_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 36\n",
      "Number of edges: 180\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (180, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# look at basic properties of the graph\n",
    "print_graph_fts(first_input_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each GraphsTuple contains a bunch of data, but what will likely be of most interest are the node features, which is what we're trying to predict. The nodes features have shape (36, 2), corresponding to the K=36 nodes which each have an X1 and X2 feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3649824 ,  0.81143504],\n",
       "       [ 0.4459807 ,  0.5750941 ],\n",
       "       [ 0.96717197, -1.0274767 ],\n",
       "       [-1.8197978 , -1.5187225 ],\n",
       "       [-0.33013806, -0.45958167],\n",
       "       [-0.12215422, -0.46869078],\n",
       "       [ 0.16023503,  0.18824354],\n",
       "       [ 0.39943892,  1.0756559 ],\n",
       "       [ 0.94749486, -1.2535653 ],\n",
       "       [-0.4739116 , -0.6680645 ],\n",
       "       [-2.2530704 , -2.022228  ],\n",
       "       [ 0.33636376, -0.7878205 ],\n",
       "       [ 0.1396998 ,  0.31165692],\n",
       "       [-0.7822607 , -0.6472315 ],\n",
       "       [ 0.03536604, -0.9326305 ],\n",
       "       [ 0.95444596, -0.43482503],\n",
       "       [ 0.582315  ,  1.6892598 ],\n",
       "       [ 0.32959026,  0.12167044],\n",
       "       [ 0.5314968 , -1.1229218 ],\n",
       "       [ 0.30201438,  0.635556  ],\n",
       "       [-0.69298774,  0.7974206 ],\n",
       "       [-1.2602797 , -0.9461577 ],\n",
       "       [-0.12644374,  0.8608444 ],\n",
       "       [ 2.0222785 ,  1.5772247 ],\n",
       "       [-0.06871947, -0.8737022 ],\n",
       "       [-1.5709201 , -0.31845146],\n",
       "       [-1.0807154 , -1.23525   ],\n",
       "       [-1.2676263 , -0.05490148],\n",
       "       [-0.59919816, -0.4760804 ],\n",
       "       [ 1.706339  ,  1.4672292 ],\n",
       "       [-0.87915367,  0.13585857],\n",
       "       [-0.6910576 ,  0.4487827 ],\n",
       "       [-1.2705714 ,  0.45159018],\n",
       "       [-1.4997728 , -0.9104107 ],\n",
       "       [ 0.5579194 ,  1.1993482 ],\n",
       "       [ 1.1419059 ,  0.6014492 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_input_graph.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a small model to get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of this don't really matter for the purpose of this notebook, so I'll just import a basic GNBlock config and setup. \n",
    "\n",
    "Note that this model is NOT trained, so the predictions will be random – it'll be used just for testing metric functions. \n",
    "\n",
    "Don't worry about any other details here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.configs import GNBlock_baseline\n",
    "model_config = GNBlock_baseline.get_config()\n",
    "\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "net = create_model(model_config, deterministic=True)\n",
    "params = jax.jit(net.init)(init_rng, first_input_window)\n",
    "\n",
    "# Create the optimizer.\n",
    "tx = create_optimizer(model_config)\n",
    "\n",
    "# Create the training state.\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=net.apply, params=params, tx=tx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get predictions using the following function call. \n",
    "\n",
    "pred_graphs_list is a list of predicted graphs (in this case it is only has single element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jraph._src.graph.GraphsTuple'>\n"
     ]
    }
   ],
   "source": [
    "pred_graphs_list = state.apply_fn(state.params, first_input_window) \n",
    "pred_graph = pred_graphs_list[0]\n",
    "print(type(pred_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.        , 0.6415052 ],\n",
       "       [0.        , 0.28648597],\n",
       "       [0.        , 0.36244932],\n",
       "       [0.10148586, 0.1256536 ],\n",
       "       [0.        , 0.0408808 ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.39947745],\n",
       "       [0.        , 0.47231084],\n",
       "       [0.        , 0.05931716],\n",
       "       [0.41900653, 0.36059526],\n",
       "       [0.        , 0.12634347],\n",
       "       [0.        , 0.04503629],\n",
       "       [0.        , 0.06245288],\n",
       "       [0.        , 0.10422921],\n",
       "       [0.        , 0.1124042 ],\n",
       "       [0.        , 0.694765  ],\n",
       "       [0.        , 0.04666549],\n",
       "       [0.        , 0.4672794 ],\n",
       "       [0.        , 0.17842755],\n",
       "       [0.        , 0.46139765],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.34355032],\n",
       "       [0.        , 0.36689094],\n",
       "       [0.        , 0.27120814],\n",
       "       [0.        , 0.05685274],\n",
       "       [0.        , 0.15074416],\n",
       "       [0.        , 0.04457913],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.3694534 ],\n",
       "       [0.        , 0.08670933],\n",
       "       [0.        , 0.42717212],\n",
       "       [0.        , 0.4719391 ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.5274234 ],\n",
       "       [0.        , 0.12584773]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_graph.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generalized implementation of MSE that uses jax numpy, which is pretty easy to substitute for regular numpy. The same should apply for jax scipy (imported above as jscipy). \n",
    "\n",
    "In this case, I treat the target and preds variables as arrays (the type doesn't matter that much, they can be jnp or np arrays, possibly even nested lists). So we can't pass a raw GraphsTuple into this, we have to specifically select the nodes attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(targets, preds):\n",
    "    mse = jnp.mean(jnp.square(preds - targets))\n",
    "    return mse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the metrics like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.0594673, dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(first_target_graph.nodes, pred_graph.nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
